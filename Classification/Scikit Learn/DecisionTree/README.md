
## Decsision Tree
	1.Decsision Tree Can solve both classification and regression problems.
	2.Decsision Tree Creates complex non-linear boundaries.
	3.Decsision Tree Decision tree looks for a solution with lower depth.
	4.Decsision Tree It is greedy.
	
## Attribute Selection in Decision Tree 
	1.Entropy.
	2.Information Gain.
	3.Gain Impurity.
	4.Chi-Square (non-parametric statistical test to understand the relationship between two categorical variables.
	  High chi-squre value means that attribute affects outputs).
	5.ANOVA (for regression).
## Adventages
	1.Interpretability.
	2.Less Data Preparation.
	3.Non-Parametric.
	4.Non-Linearity.
	5.Versatility.
## Disadventages

	1.Overfitting (post and pre pruning can help to solve this problem).
	2.Feature Reduction & Data Resampling.
	3.Unstable.
	4.Decision trees are high variance models.
	5.Time consuming in training phase.
	
## Tree algorithms 
	1.ID3
	2.C4.5
	3.C5.0
	4.CART


