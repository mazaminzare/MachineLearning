Decsision Tree:
•	Can solve both classifications and regression problems.
•	Creates complex non-linear boundaries.
•	Decision tree looks for a solution with lower depth 
•	It is greedy.
Attribute Selection in Decision Tree : 
•	Entropy.
•	Information Gain .
•	Gain Impurity.
•	Chi-Square (non-parametric statistical test to understand the relationship between two categorical variables. High chi-squre value means that attribute affects outputs).
•	ANOVA (for regression)
Adventages:
•	Interpretability.
•	Less Data Preparation.
•	Non-Parametric.
•	Non-Linearity.
•	Versatility.
Disadventages:
•	Overfitting (post and pre pruning can help to solve this problem).
•	Feature Reduction & Data Resampling.
•	Unstable.
•	Decision trees are high variance models.
•	Time consuming in training phase

	
